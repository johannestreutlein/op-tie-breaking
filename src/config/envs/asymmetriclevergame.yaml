env: asymmetriclevergame

env_args:

  r_success: 1
  r_failure: -1

  n_comm_steps: 0
  episode_limit: 4
  extra_action: 1
  title: 'asymmetriclevergame'

#True since this game doesn't have symmetric players
obs_agent_id: True # Include the agent's one_hot id in the observation

#I include the agent's action manually in the observation, so this is false
obs_last_action: False # Include the agent's last action (one_hot) in the observation

#we train for 5 million environment steps (model is saved after 5003264 steps)
t_max: 5100000 # Stop running after this many timesteps

entropy_alpha: 0.5 #entropy regularization hyperparameter for policy_gradient